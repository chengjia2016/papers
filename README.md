# papers
Some note when reading papers

## Image captioning

[1 m-RNN](https://github.com/wang-yang/papers/blob/master/image_caption/1_deep_captioning_with_m_rnn.md)

[2 DCC-without-paired-training-data](https://github.com/wang-yang/papers/blob/master/image_caption/2_deep_compositional_captioning_novel_object_without_paired_training_data.md)

[3 unambiguous-object-descriptions](https://github.com/wang-yang/papers/blob/master/image_caption/3_generation_and_comprehension_of_unambiguous_object_descriptions.md)

[4 show-and-tell](https://github.com/wang-yang/papers/blob/master/image_caption/4_show_and_tell.md)

[5 show-attend-and-tell](https://github.com/wang-yang/papers/blob/master/image_caption/5_show_attend_and_tell.md)

[6 sequence_to_sequence_video_to_text](https://github.com/wang-yang/papers/blob/master/image_caption/6_sequence_to_sequence_video_to_text.md)

## Image QA

[stacked-attention-networks](https://github.com/wang-yang/papers/blob/master/image_qa/stacked_attention_networks_for_image_question_answering.md)

## Object dectection

[r-cnn](https://github.com/wang-yang/papers/blob/master/object_dection/faster_rcnn_towards_realtime_object_dectection_with_region_proposal_networks.md)
