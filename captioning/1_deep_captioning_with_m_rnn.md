# Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)

## ICLR 2015

## 摘要

本作呈现了一个多模型RNN(m-RNN）用于产生描述新图片。对给定一张图片和一组词语，去建模生成一个词的概率分布。图片的描述就是利用这个分布采样而成。这个模型包含两部分：一个用于句子的RNN和一个用于图像的CNN。这两个网络通过多模型层彼此交互形成一个完整的m-RNN模型。本模型的有效性通过4个数据集检测（IAPR TC-12, Flickr 8K, Flickr 30K, MSCOCO），并且效果超过其他现有方法。另外我们应用m-RNN模型到图片或者句子的检索任务并远超其他现有方法。本项目的地址是：www.stat.ucla.edu/~junhua.mao/m-RNN.html

In this paper, we present a multimodal Recurrent Neural Network (m-RNN) model for generating novel image captions. It directly models the probability distribution of generating a word given previous words and an image. Image captions are generated by sampling from this distribution. The model consists of two sub-networks: a deep recurrent neural network for sentences and a deep convolutional network for images. These two sub-networks interact with each other in a multimodal layer to form the whole m-RNN model. The effectiveness of our model is validated on four benchmark datasets (IAPR TC-12, Flickr 8K, Flickr 30K and MS COCO). Our model outperforms the state-of-the-art methods. In addition, we apply the m-RNN model to retrieval tasks for retrieving images or sentences, and achieves significant performance improvement over the state-of-the-art methods which directly optimize the ranking objective function for retrieval. The project page of this work is: www.stat.ucla.edu/~junhua.mao/m-RNN.html .

## 代码

<https://github.com/mjhucla/TF-mRNN>

Tensorflow

## 备注
[Junhua Mao](http://www.stat.ucla.edu/~junhua.mao/)有很多以tf训练的模型，多看看。一系列的image captioning文章。

## 作者

Junhua Mao, Wei Xu & Yi Yang & Jiang Wang & Zhiheng Huang, Alan Yuille
